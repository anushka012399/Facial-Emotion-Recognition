{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.8/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/lib/python3.8/site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.8/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from h5py->keras) (1.15.0)\n",
      "Requirement already satisfied: keras_vggface in /opt/anaconda3/lib/python3.8/site-packages (0.6)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda3/lib/python3.8/site-packages (from keras_vggface) (1.5.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.8/site-packages (from keras_vggface) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from keras_vggface) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.8/site-packages (from keras_vggface) (5.3.1)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.8/site-packages (from keras_vggface) (7.2.0)\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.8/site-packages (from keras_vggface) (2.4.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.8/site-packages (from keras_vggface) (1.15.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: scikit_image in /opt/anaconda3/lib/python3.8/site-packages (0.16.2)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit_image) (1.5.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit_image) (7.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit_image) (2.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit_image) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit_image) (3.2.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit_image) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/anaconda3/lib/python3.8/site-packages (from scipy>=0.19.0->scikit_image) (1.18.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->scikit_image) (4.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit_image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit_image) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit_image) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit_image) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit_image) (1.15.0)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/anaconda3/lib/python3.8/site-packages (from h5py) (1.18.5)\n",
      "Requirement already satisfied: keras_applications in /opt/anaconda3/lib/python3.8/site-packages (1.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.8/site-packages (from keras_applications) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from keras_applications) (1.18.5)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from h5py->keras_applications) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install keras_vggface\n",
    "!pip install pandas\n",
    "!pip install scikit_image\n",
    "!pip install h5py\n",
    "!pip install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense \n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.lib.io import file_io\n",
    "from skimage.transform import resize\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger,TensorBoard, LearningRateScheduler,Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Activation, Convolution2D, Conv2D, Dropout, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Input, MaxPooling2D, SeparableConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 197, 197\n",
    "num_classes         = 7     \n",
    "epochs_top_layers   = 5\n",
    "epochs_all_layers   = 100\n",
    "batch_size          = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGGFace(\n",
    "    model       = 'resnet50',\n",
    "    include_top = False,\n",
    "    weights     = 'vggface',\n",
    "    input_shape = (img_height, img_width, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "predictions = Dense(num_classes, activation = 'softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = base_model.input, outputs = predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x -= 128.8006 \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset):\n",
    "    file_stream = file_io.FileIO(dataset, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    images = np.empty((len(data), img_height, img_width, 3))\n",
    "    i = 0\n",
    "\n",
    "    for pixel_sequence in pixels:\n",
    "        single_image = [float(pixel) for pixel in pixel_sequence.split(' ')]  \n",
    "        single_image = np.asarray(single_image).reshape(48, 48)\n",
    "        single_image = resize(single_image, (img_height, img_width), order = 3, mode = 'constant') \n",
    "        ret = np.empty((img_height, img_width, 3))  \n",
    "        ret[:, :, 0] = single_image\n",
    "        ret[:, :, 1] = single_image\n",
    "        ret[:, :, 2] = single_image\n",
    "        images[i, :, :, :] = ret\n",
    "        i += 1\n",
    "    \n",
    "    images = preprocess_input(images)\n",
    "    labels = to_categorical(data['emotion'])\n",
    "\n",
    "    return images, labels    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset='/Users/anushkapatil/Desktop/thesis/training_dataset.csv'\n",
    "eval_dataset='/Users/anushkapatil/Desktop/thesis/eval_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x, train_data_y  = get_data(train_dataset)\n",
    "val_data  = get_data(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range  = 10,\n",
    "    shear_range     = 10, # 10 degrees\n",
    "    zoom_range      = 0.1,\n",
    "    fill_mode       = 'reflect',\n",
    "    horizontal_flip = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(\n",
    "    train_data_x,\n",
    "    train_data_y,\n",
    "    batch_size  = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder= '/Users/anushkapatil/Desktop/thesis/ResNet-50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer   = Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0), \n",
    "    loss        = 'categorical_crossentropy', \n",
    "    metrics     = ['accuracy'])\n",
    "tensorboard_top_layers = TensorBoard(\n",
    "    log_dir         = folder + '/logs_top_layers',\n",
    "    histogram_freq  = 0,\n",
    "    write_graph     = True,\n",
    "    write_grads     = False,\n",
    "    write_images    = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    generator           = train_generator,\n",
    "    steps_per_epoch     = len(train_data_x) // batch_size, \n",
    "    epochs              = epochs_top_layers,                            \n",
    "    validation_data     = val_data,\n",
    "    callbacks           = [tensorboard_top_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer   = SGD(lr = 1e-4, momentum = 0.9, decay = 0.0, nesterov = True),\n",
    "    loss        = 'categorical_crossentropy', \n",
    "    metrics     = ['accuracy'])\n",
    "\n",
    "tensorboard_all_layers = TensorBoard(\n",
    "    log_dir         = folder + '/logs_all_layers',\n",
    "    histogram_freq  = 0,\n",
    "    write_graph     = True,\n",
    "    write_grads     = False,\n",
    "    write_images    = True)\n",
    "\n",
    "def scheduler(epoch):\n",
    "    updated_lr = K.get_value(model.optimizer.lr) * 0.5\n",
    "    if (epoch % 3 == 0) and (epoch != 0):\n",
    "        K.set_value(model.optimizer.lr, updated_lr)\n",
    "        print(K.get_value(model.optimizer.lr))\n",
    "    return K.get_value(model.optimizer.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_plateau = ReduceLROnPlateau(monitor = 'val_loss',factor= 0.5,patience= 3,mode = 'auto',min_lr= 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_loss',patience= 10,mode= 'auto')\n",
    "\n",
    "class ModelCheckpoint(Callback):\n",
    "\n",
    "def __init__(self, filepath, folder, monitor = 'val_loss', verbose = 0, save_best_only = False, save_weights_only = False, mode = 'auto', period = 1):\n",
    "super(ModelCheckpoint, self).__init__()\n",
    "self.monitor = monitor\n",
    "self.verbose= verbose\n",
    "self.filepath= filepath\n",
    "self.folder= folder\n",
    "self.save_best_only= save_best_only\n",
    "self.save_weights_only= save_weights_only\n",
    "self.period= period\n",
    "self.epochs_since_last_save\t= 0\n",
    "\n",
    "if mode not in ['auto', 'min', 'max']:\n",
    "warnings.warn('ModelCheckpoint mode %s is unknown, ' 'fallback to auto mode.' % (mode), RuntimeWarning)\n",
    "mode = 'auto'\n",
    "if mode == 'min':\n",
    "    self.monitor_op = np.less\n",
    "    self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                    self.monitor_op = np.greater\n",
    "                    self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch = epoch + 1, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                   warnings.warn('Can save best model only with %s available, ' 'skipping.' % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,' ' saving model to %s' % (epoch + 1, self.monitor, self.best, current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.model.save(filepath, overwrite=True)\n",
    "                           \n",
    "                            with file_io.FileIO(filepath, mode='r') as input_f:\n",
    "                                with file_io.FileIO(self.folder + '/checkpoints/' + filepath, mode='w+') as output_f:\n",
    "                                    output_f.write(input_f.read())\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('\\nEpoch %05d: %s did not improve' %\n",
    "                                  (epoch + 1, self.monitor))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.model.save(filepath, overwrite=True)\n",
    "                \n",
    "                    with file_io.FileIO(filepath, mode='r') as input_f:\n",
    "                        with file_io.FileIO(self.folder + '/checkpoints/' + filepath, mode='w+') as output_f:\n",
    "                            output_f.write(input_f.read())\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = ModelCheckpoint(\n",
    "    filepath= 'ResNet-50_{epoch:02d}_{val_loss:.2f}.h5',\n",
    "    folder= folder,\n",
    "    monitor= 'val_loss', \n",
    "    save_best_only= True,\n",
    "    mode= 'auto',\n",
    "    period= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    generator           = train_generator,\n",
    "    steps_per_epoch     = len(train_data_x) // batch_size,  \n",
    "    epochs              = epochs_all_layers,                        \n",
    "    validation_data     = val_data,\n",
    "    callbacks           = [tensorboard_all_layers, reduce_lr, reduce_lr_plateau, early_stop, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder + '/ResNet-50.h5')\n",
    "\n",
    "with file_io.FileIO('ResNet-50.h5', mode='r') as input_f:\n",
    "    with file_io.FileIO(folder + '/ResNet-50.h5', mode='w+') as output_f:\n",
    "        output_f.write(input_f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
